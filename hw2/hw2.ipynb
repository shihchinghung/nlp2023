{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b481f268",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/ry/phxc250s3lx_m2h646xkjb1h0000gn/T/jieba.cache\n",
      "Loading model cost 0.700 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import jieba\n",
    "\n",
    "url = 'https://movies.yahoo.com.tw/category.html'\n",
    "response = requests.get(url)\n",
    "html = response.text\n",
    "\n",
    "soup = BeautifulSoup(html, 'html.parser')\n",
    "links = soup.select('.video_category_list.category-list ._slickcontent a')\n",
    "url_queue = []\n",
    "for link in links:\n",
    "    url_queue.append(link['href'])\n",
    "\n",
    "def crawl_yahoo_movies(i):\n",
    "    current_url = url_queue.pop(0)\n",
    "    movie_id = current_url.split('/')[-1]\n",
    "    url = f'https://movies.yahoo.com.tw/movieinfo_main/{movie_id}'\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    movie_list = []\n",
    "    #for movie_elem in soup.select('.release_list .release_info'):\n",
    "    movie = {}\n",
    "    url_parts = url.split(\"-\")\n",
    "    id_part = url_parts[-1].split(\"/\")\n",
    "    movie['doc_id'] = id_part[-1]  # doc_id\n",
    "    movie['cname'] = soup.select_one('.movie_intro_info_r h1').text.strip()  # 中文片名\n",
    "    movie['ename'] = soup.select_one('.movie_intro_info_r h3').text.strip() # 英文片名\n",
    "    movie['pagerank'] = \"\" # PageRank\n",
    "    movie['label'] = soup.select_one('.level_name').text.strip() # label\n",
    "    movie['intro'] = soup.select_one('.gray_infobox_inner span').text.strip() # 劇情簡介\n",
    "    movie['released_date'] = soup.find(\"div\", class_=\"movie_intro_info_r\").find_all(\"span\")[0].text.strip() # 上映日期\n",
    "    movie['links'] = url\n",
    "    movie_list.append(movie)\n",
    "    url_queue.append(current_url)\n",
    "    return movie_list\n",
    "\n",
    "all_movies = []\n",
    "for i in range(1, 10001):\n",
    "    all_movies.extend(crawl_yahoo_movies(i))\n",
    "    if len(all_movies) >= 10000:\n",
    "        break\n",
    "\n",
    "# 建立Inverted Index\n",
    "inverted_index = {}\n",
    "for movie in all_movies:\n",
    "    doc_id = movie['doc_id']\n",
    "    cname = movie['cname']\n",
    "    ename = movie['ename']\n",
    "    pagerank = movie['pagerank']\n",
    "    label = movie['label']\n",
    "    intro = movie['intro']\n",
    "    released_date = movie['released_date']\n",
    "    links = movie['links']\n",
    "    cname_words = jieba.lcut(cname) # 中文分詞\n",
    "    intro_words = jieba.lcut(intro)\n",
    "    for word in cname_words + intro_words:\n",
    "        if word not in inverted_index:\n",
    "            inverted_index[word] = []\n",
    "        inverted_index[word].append(doc_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7e0da8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hungshihching/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.2\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "G = nx.DiGraph()\n",
    "for movie in all_movies:\n",
    "    G.add_node(movie['doc_id'])\n",
    "    for term in movie['cname'].split() + movie['ename'].split():\n",
    "        if term in inverted_index:\n",
    "            for doc_id in inverted_index[term]:\n",
    "                if doc_id != movie['doc_id']:\n",
    "                    G.add_edge(doc_id, movie['doc_id'])\n",
    "\n",
    "pagerank_values = nx.pagerank(G) # PageRank\n",
    "for movie in all_movies:\n",
    "    movie['pagerank'] = round(pagerank_values[movie['doc_id']], 5) # 取到小數第5位\n",
    "\n",
    "all_movies.sort(key=lambda x: x['pagerank'], reverse=True)# 按照 PageRank 值從高到低進行排序"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2472714e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 存JSON\n",
    "with open('hw2.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(all_movies, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "with open('inverted_index.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(inverted_index, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e53a9a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "請輸入搜尋關鍵字: 最美麗\n",
      "您的搜尋結果 (Sorting by PageRank Value)：共 2 筆，符合” 最美麗 “  - - - 共 indexing 10000 筆電影資料\n",
      "14979 (0.08333)中文片名: 最美麗的小事\n",
      "                                              (2023)\n",
      "14979 (0.08333)劇情介紹: 《最美麗的小事》根據雪兒史翠德的暢銷小說集改編，女主角婚姻即將告終。女兒幾乎不和她說話。曾經一片光明的寫作生涯無疾而終。所以當一個朋友建議她接手撰寫諮商專欄時，她認為自己根本沒資格擔任這份工作…事實上，她也許是最有資格的人。\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('hw2.json', 'r', encoding='utf-8') as f:\n",
    "    all_movies = json.load(f)\n",
    "\n",
    "term = input(\"請輸入搜尋關鍵字: \")\n",
    "movies = [] # 放符合關鍵字的電影資料\n",
    "matched_movies = 0 # 符合關鍵字數量\n",
    "# search\n",
    "for movie in all_movies:\n",
    "    if term in movie['cname'] and term in movie['intro']: # cname & intro\n",
    "        movies.append(movie)\n",
    "        print(\"您的搜尋結果 (Sorting by PageRank Value)：共 \", len(movies), \" 筆，符合”\", term, \"“  - - - 共 indexing\",  len(all_movies), \"筆電影資料\")\n",
    "        print(\"{} ({})中文片名: {}\".format(movie['doc_id'], movie['pagerank'], movie['cname']))\n",
    "        print(\"{} ({})劇情介紹: {}\".format(movie['doc_id'], movie['pagerank'], movie['intro']))\n",
    "        print(\"===\" * 10)\n",
    "        matched_movies += 1\n",
    "    elif term in movie['cname']: # cname\n",
    "        movies.append(movie)\n",
    "        print(\"您的搜尋結果 (Sorting by PageRank Value)：共 \", len(movies), \" 筆，符合”\", term, \"“  - - - 共 indexing\",  len(all_movies), \"筆電影資料\")\n",
    "        print(\"{} ({})中文片名: {}\".format(movie['doc_id'], movie['pagerank'], movie['cname']))\n",
    "        print(\"===\" * 10)\n",
    "        matched_movies += 1\n",
    "    elif term in movie['intro']: #intro\n",
    "        movies.append(movie)\n",
    "        print(\"您的搜尋結果 (Sorting by PageRank Value)：共 \", len(movies), \" 筆，符合”\", term, \"“  - - - 共 indexing\",  len(all_movies), \"筆電影資料\")\n",
    "        print(\"{} ({})劇情介紹: {}\".format(movie['doc_id'], movie['pagerank'], movie['intro']))\n",
    "        print(\"===\" * 10)\n",
    "        matched_movies += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ce862e4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 70.00%\n",
      "Recall: 20.00%\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import jieba\n",
    "from collections import defaultdict\n",
    "\n",
    "class MovieSearchEngine:\n",
    "    def __init__(self, movies, inverted_index):\n",
    "        self.movies = movies\n",
    "        self.inverted_index = inverted_index\n",
    "\n",
    "    def search(self, query):\n",
    "        query_terms = list(jieba.cut(query))\n",
    "        query_ids = set()\n",
    "        for term in query_terms:\n",
    "            if term in self.inverted_index:\n",
    "                query_ids.update(self.inverted_index[term])\n",
    "        query_ids = list(query_ids)\n",
    "        query_ids.sort(key=lambda x: self.movies[x]['pagerank'], reverse=True)\n",
    "        # 計算 precision, recall\n",
    "        relevant_count = 0\n",
    "        for movie_id in query_ids:\n",
    "            if query in self.movies[movie_id]['cname'] or query in self.movies[movie_id]['ename']:\n",
    "                relevant_count += 1\n",
    "        precision = relevant_count / len(query_ids)\n",
    "        recall = relevant_count / len(self.movies)\n",
    "        print(\"Precision: {:.2%}\".format(precision))\n",
    "        print(\"Recall: {:.2%}\".format(recall))\n",
    "\n",
    "with open('hw2.json', 'r', encoding='utf-8') as f:\n",
    "    movies_data = json.load(f)\n",
    "\n",
    "movies = {}\n",
    "for movie_data in movies_data:\n",
    "    movies[movie_data['doc_id']] = movie_data\n",
    "\n",
    "inverted_index = defaultdict(set)\n",
    "for movie_id, movie_data in movies.items():\n",
    "    for term in jieba.cut(movie_data['cname']):\n",
    "        inverted_index[term].add(movie_id)\n",
    "    for term in jieba.cut(movie_data['ename']):\n",
    "        inverted_index[term].add(movie_id)\n",
    "\n",
    "search_engine = MovieSearchEngine(movies, inverted_index)\n",
    "search_engine.search(term)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6f4b98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 454.772252,
   "end_time": "2022-08-28T11:09:43.359324",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-08-28T11:02:08.587072",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
